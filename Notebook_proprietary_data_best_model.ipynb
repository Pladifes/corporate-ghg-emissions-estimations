{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mohamed.fahmaoui\\.virtualenvs\\corporate_ghg_estimation-2wWrtO8D\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from functions.loading import load_data\n",
    "from functions.merged_dataset_creation import create_preprocessed_dataset\n",
    "from functions.training_pipeline import training_pipeline\n",
    "from functions.models import xgboost_model, catboost_model, lgbm_model\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.mode.chained_assignment = None\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters defintion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_rawdata = 'data/raw_data/'\n",
    "path_models = 'models/proprietary_data/'\n",
    "path_Benchmark = 'Benchmark/'\n",
    "path_results = 'results/proprietary_data/'\n",
    "path_plot = path_results +'plot/'\n",
    "path_intermediary = 'data/intermediary_data/proprietary_data/'\n",
    "path_plot = 'results/proprietary_data/plot/'\n",
    "# ,\"CF3_log\", \"CF123_log\"\n",
    "targets = [\"CF1_log\",\"CF2_log\",\"CF3_log\", \"CF123_log\"]\n",
    "models = {\n",
    "        \"xgboost\": xgboost_model,\n",
    "        \"catboost\": catboost_model,\n",
    "        \"lgbm\": lgbm_model,\n",
    "}\n",
    "training_parameters = {\n",
    "    \"low\":0.01,\n",
    "    \"high\":1,\n",
    "    \"extended_features\": [\n",
    "            \"Revenue_log\",\n",
    "            \"EMP_log\",\n",
    "            \"Asset_log\",\n",
    "            \"NPPE_log\",\n",
    "            \"CapEx_log\",\n",
    "            \"Age\",\n",
    "            \"CapInten\",\n",
    "            \"GMAR\",\n",
    "            \"Leverage\",\n",
    "            \"Price\",\n",
    "            \"FuelIntensity\",\n",
    "            \"FiscalYear\",\n",
    "            \"ENEConsume_log\",\n",
    "            \"ENEProduce_log\",\n",
    "            \"INTAN_log\",\n",
    "            \"AccuDep_log\",\n",
    "            \"COGS_log\",\n",
    "        ],\n",
    "    \"selec_sect\":[\"GICSSubInd\", \"GICSInd\", \"GICSGroup\"],\n",
    "    \"fill_grp\":\"\",\n",
    "    \"old_pipe\":False,  \n",
    "    \"cross_val\": False,\n",
    "}\n",
    "\n",
    "Summary_Final=[]\n",
    "ensemble =[]\n",
    "summary_metrics_detailed = pd.DataFrame()\n",
    "estimated_scopes = []"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and save best models for proprietary data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Refinitiv_data, CarbonPricing, IncomeGroup, FuelIntensity, GICSReclass = load_data(path_rawdata) \n",
    "        \n",
    "preprocessed_dataset = create_preprocessed_dataset(\n",
    "    Refinitiv_data,\n",
    "    GICSReclass,\n",
    "    CarbonPricing,\n",
    "    IncomeGroup,\n",
    "    FuelIntensity) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/05/03 18:22:51 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n",
      "Registered model 'xgboost' already exists. Creating a new version of this model...\n",
      "2023/05/03 18:23:09 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation.                     Model name: xgboost, version 5\n",
      "Created version '5' of model 'xgboost'.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m summary_metrics_detailed \u001b[39m=\u001b[39m training_pipeline(\n\u001b[0;32m      2\u001b[0m     name_experiment\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mbest_models_on_proprietary_data_mohamed24\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m      3\u001b[0m     path_Benchmark\u001b[39m=\u001b[39;49mpath_Benchmark,\n\u001b[0;32m      4\u001b[0m     path_results\u001b[39m=\u001b[39;49mpath_results,\n\u001b[0;32m      5\u001b[0m     path_models\u001b[39m=\u001b[39;49mpath_models,\n\u001b[0;32m      6\u001b[0m     path_intermediary\u001b[39m=\u001b[39;49mpath_intermediary,\n\u001b[0;32m      7\u001b[0m     path_plot \u001b[39m=\u001b[39;49m path_plot,\n\u001b[0;32m      8\u001b[0m     targets\u001b[39m=\u001b[39;49mtargets,\n\u001b[0;32m      9\u001b[0m     models\u001b[39m=\u001b[39;49mmodels,\n\u001b[0;32m     10\u001b[0m     Summary_Final\u001b[39m=\u001b[39;49mSummary_Final,\n\u001b[0;32m     11\u001b[0m     ensemble\u001b[39m=\u001b[39;49mensemble,\n\u001b[0;32m     12\u001b[0m     summary_metrics_detailed\u001b[39m=\u001b[39;49msummary_metrics_detailed,\n\u001b[0;32m     13\u001b[0m     estimated_scopes \u001b[39m=\u001b[39;49m estimated_scopes,\n\u001b[0;32m     14\u001b[0m     preprocessed_dataset\u001b[39m=\u001b[39;49mpreprocessed_dataset,\n\u001b[0;32m     15\u001b[0m     training_parameters\u001b[39m=\u001b[39;49mtraining_parameters,\n\u001b[0;32m     16\u001b[0m     open_data\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m     17\u001b[0m     save\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m     18\u001b[0m     \n\u001b[0;32m     19\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\mohamed.fahmaoui\\Projets\\corporate-ghg-emissions-estimations\\functions\\training_pipeline.py:75\u001b[0m, in \u001b[0;36mtraining_pipeline\u001b[1;34m(name_experiment, path_Benchmark, path_results, path_models, path_intermediary, path_plot, targets, models, Summary_Final, ensemble, summary_metrics_detailed, estimated_scopes, preprocessed_dataset, training_parameters, open_data, save)\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[39mfor\u001b[39;00m i, (model_name, model) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(models\u001b[39m.\u001b[39mitems()):\n\u001b[0;32m     74\u001b[0m     \u001b[39mwith\u001b[39;00m mlflow\u001b[39m.\u001b[39mstart_run() \u001b[39mas\u001b[39;00m run:\n\u001b[1;32m---> 75\u001b[0m         model_i \u001b[39m=\u001b[39m model(\n\u001b[0;32m     76\u001b[0m             X_train,\n\u001b[0;32m     77\u001b[0m             y_train,\n\u001b[0;32m     78\u001b[0m             cross_val\u001b[39m=\u001b[39;49mtraining_parameters[\u001b[39m\"\u001b[39;49m\u001b[39mcross_val\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m     79\u001b[0m             n_jobs\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m,\n\u001b[0;32m     80\u001b[0m             verbose\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m,\n\u001b[0;32m     81\u001b[0m             n_iter\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m,\n\u001b[0;32m     82\u001b[0m             seed\u001b[39m=\u001b[39;49m\u001b[39m42\u001b[39;49m,\n\u001b[0;32m     83\u001b[0m         )\n\u001b[0;32m     84\u001b[0m         y_pred \u001b[39m=\u001b[39m model_i\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[0;32m     86\u001b[0m         summary_global, rmse, std \u001b[39m=\u001b[39m metrics(\n\u001b[0;32m     87\u001b[0m             y_test, y_pred, Summary_Final, target, model_name\n\u001b[0;32m     88\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\mohamed.fahmaoui\\Projets\\corporate-ghg-emissions-estimations\\functions\\models.py:265\u001b[0m, in \u001b[0;36mcatboost_model\u001b[1;34m(X_train, y_train, cross_val, n_jobs, verbose, n_iter, seed)\u001b[0m\n\u001b[0;32m    253\u001b[0m     catboost_bo\u001b[39m.\u001b[39mmaximize(init_points\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m, n_iter\u001b[39m=\u001b[39mn_iter, acq\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mei\u001b[39m\u001b[39m\"\u001b[39m, xi\u001b[39m=\u001b[39m\u001b[39m0.0\u001b[39m)\n\u001b[0;32m    255\u001b[0m     model \u001b[39m=\u001b[39m CatBoostRegressor(\n\u001b[0;32m    256\u001b[0m         verbose\u001b[39m=\u001b[39mverbose,\n\u001b[0;32m    257\u001b[0m         random_state\u001b[39m=\u001b[39mseed,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    263\u001b[0m         \u001b[39m# iterations=catboost_bo.max[\"params\"][\"iterations\"]\u001b[39;00m\n\u001b[0;32m    264\u001b[0m     )\n\u001b[1;32m--> 265\u001b[0m model\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m    266\u001b[0m \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[1;32mc:\\Users\\mohamed.fahmaoui\\.virtualenvs\\corporate_ghg_estimation-2wWrtO8D\\lib\\site-packages\\catboost\\core.py:5730\u001b[0m, in \u001b[0;36mCatBoostRegressor.fit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m   5727\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mloss_function\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m params:\n\u001b[0;32m   5728\u001b[0m     CatBoostRegressor\u001b[39m.\u001b[39m_check_is_compatible_loss(params[\u001b[39m'\u001b[39m\u001b[39mloss_function\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m-> 5730\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y, cat_features, text_features, embedding_features, \u001b[39mNone\u001b[39;49;00m, sample_weight, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, baseline,\n\u001b[0;32m   5731\u001b[0m                  use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description,\n\u001b[0;32m   5732\u001b[0m                  verbose_eval, metric_period, silent, early_stopping_rounds,\n\u001b[0;32m   5733\u001b[0m                  save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\n",
      "File \u001b[1;32mc:\\Users\\mohamed.fahmaoui\\.virtualenvs\\corporate_ghg_estimation-2wWrtO8D\\lib\\site-packages\\catboost\\core.py:2355\u001b[0m, in \u001b[0;36mCatBoost._fit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m   2351\u001b[0m allow_clear_pool \u001b[39m=\u001b[39m train_params[\u001b[39m\"\u001b[39m\u001b[39mallow_clear_pool\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   2353\u001b[0m \u001b[39mwith\u001b[39;00m log_fixup(log_cout, log_cerr), \\\n\u001b[0;32m   2354\u001b[0m     plot_wrapper(plot, plot_file, \u001b[39m'\u001b[39m\u001b[39mTraining plots\u001b[39m\u001b[39m'\u001b[39m, [_get_train_dir(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_params())]):\n\u001b[1;32m-> 2355\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train(\n\u001b[0;32m   2356\u001b[0m         train_pool,\n\u001b[0;32m   2357\u001b[0m         train_params[\u001b[39m\"\u001b[39;49m\u001b[39meval_sets\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m   2358\u001b[0m         params,\n\u001b[0;32m   2359\u001b[0m         allow_clear_pool,\n\u001b[0;32m   2360\u001b[0m         train_params[\u001b[39m\"\u001b[39;49m\u001b[39minit_model\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[0;32m   2361\u001b[0m     )\n\u001b[0;32m   2363\u001b[0m \u001b[39m# Have property feature_importance possibly set\u001b[39;00m\n\u001b[0;32m   2364\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_object\u001b[39m.\u001b[39m_get_loss_function_name()\n",
      "File \u001b[1;32mc:\\Users\\mohamed.fahmaoui\\.virtualenvs\\corporate_ghg_estimation-2wWrtO8D\\lib\\site-packages\\catboost\\core.py:1759\u001b[0m, in \u001b[0;36m_CatBoostBase._train\u001b[1;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[0;32m   1758\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_train\u001b[39m(\u001b[39mself\u001b[39m, train_pool, test_pool, params, allow_clear_pool, init_model):\n\u001b[1;32m-> 1759\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_object\u001b[39m.\u001b[39;49m_train(train_pool, test_pool, params, allow_clear_pool, init_model\u001b[39m.\u001b[39;49m_object \u001b[39mif\u001b[39;49;00m init_model \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m   1760\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_trained_model_attributes()\n",
      "File \u001b[1;32m_catboost.pyx:4623\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_catboost.pyx:4672\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "summary_metrics_detailed = training_pipeline(\n",
    "    name_experiment=\"best_models_on_proprietary_data_mohamed24\",\n",
    "    path_Benchmark=path_Benchmark,\n",
    "    path_results=path_results,\n",
    "    path_models=path_models,\n",
    "    path_intermediary=path_intermediary,\n",
    "    path_plot = path_plot,\n",
    "    targets=targets,\n",
    "    models=models,\n",
    "    Summary_Final=Summary_Final,\n",
    "    ensemble=ensemble,\n",
    "    summary_metrics_detailed=summary_metrics_detailed,\n",
    "    estimated_scopes = estimated_scopes,\n",
    "    preprocessed_dataset=preprocessed_dataset,\n",
    "    training_parameters=training_parameters,\n",
    "    open_data=False,\n",
    "    save=True,\n",
    "    \n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('Toy_project_mohamed-WRM7iGFq')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e5804064e154bb9b061cd7fd0f83281b098d9543a7756d48d130cd8f20723185"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
